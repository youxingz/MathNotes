# Examples of Rings

## Polynomial Rings

Fix a commutative ring $R$ with identity. We define the ring of polynomials in a form which may already be familiar, at least for polynomials with real coefficients. A definition in terms of Cartesian products is given in Appendix I.

Let $x$ be an indeterminate. The formal sum
$$
a_nx^n + a_{n-1}x^{n-1}+\cdots +a_1x+a_0
$$
with $n\geq0$ and each $a_i\in R$ is called a polynomial in $x$ with coefficients $a_i$ in $R$.

If $a_n\neq 0$, then the polynomial is said to be of `degree` $n$, $a_nx^n$ is called the `leading term`, and $a_n$ is called the `leading coefficient`. The polynomial is `monic` if $a_n=1$. The set of all such polynomials is called the ring of `polynomials in the variable` $x$ `with coefficients in` $R$ and will be denoted $R[x]$.

The operations of addition and multiplication which make $R[x]$ into a ring are same operations familiar from elementary algebra: addition is "componentwise", multiplication is performed by first defining $(ax^i)(bx^j)=abx^{i+j}$ for polynomials with only one nonzero term and then extending to all polynomials by the distributive laws.
$$
\sum a_i x^i \sum b_i x^i = \sum a_i b_j x^{i+j}
$$

The ring $R$ appears in $R[x]$ as the `constant polynomials`. Note that by definition of the multiplication, $R[x]$ is a `commutative ring with identity` (the identity $1$ from $R$).

The coefficient ring $R$ above was assumed to be a commutative ring since that is the situation we shall be primarily interested in, but note that the definition of the addition and multiplication in $R[x]$ above would be valid even if $R$ were not commutative or did not have an identity. If the coefficient ring $R$ is the integers $\Z$ (or $\mathbb Q$), the polynomial ring $\Z[x]$ (or $\mathbb Q$) is the ring of polynomials with integer (or rational) coefficients familiar from elementary algebra.

Another example is the polynomial ring $\Z/3\Z[x]$ of polynomials in $x$ with coefficients in $\Z/3\Z$. This ring consists of nonnegative powers of $x$ with coefficients $0,1,2$ with calculations on the coefficients performed modulo $3$. For example, if
$$
p(x)=x^2+2x+1\qquad \text{and} \qquad q(x)=x^3+x+2
$$
then
$$
p(x)+q(x)=x^3+x^2\\
p(x)q(x)=x^5 + 2x^4+2x^3+x^2+2x+2
$$
The ring in which the coefficients are taken makes a substantial difference in the behavior of polynomials. For example, the polynomial $x^2+1$ is not a perfect square in the polynomial ring $\Z[x]$, but is a perfect square in the polynomial ring $\Z/2\Z[x]$, since $(x+1)^2=x^2+2x+1=x^2+1$ in this ring.

### Proposition

Let $R$ be an integral domain and let $p(x), q(x)$ be nonzero elements of $R[x]$. Then
1. degree $p(x)q(x)=$ degree $p(x)$ + degree $q(x)$,
2. the units of $R[x]$ are just the units of $R$,
3. $R[x]$ is an integral domain.

Proof of 2: If $p(x)$ is a unit, say $p(x)q(x)=1$, then degree $p(x) +$ degree $q(x) = 0$, hence $p(x),q(x)$ must in $R$.

If the ring $R$ has zero divisors then so does $R[x]$, because $R\subset R[x]$. Also, if $f(x)$ is a zero divisor in $R[x]$, then in fact $cf(x)=0$ for some nonzero $c\in R$.

If $S$ is a subring of $R$ then $S[x]$ is a subring of $R[x]$ (Consider example: $\Z[x]$ is a subring of $\mathbb Q[x]$). Some other examples of subrings of $R[x]$ are the set of all polynomials in $x^2$ (i.e., only even powers appear) and the set of all polynomials with zero constant term.

## Matrix Rings

Fix an arbitrary ring $R$ and let $n$ be a positive integer. Let $M_n(R)$ be the set of all $n\times n$ `matrices with entries from` $R$. The element $(a_{ij})$ of $M_n(R)$ is an $n\times n$ square array of elements of $R$ whose entry in row $i$ and column $j$ is $a_{ij}\in R$. The set of matrices becomes a ring under the usual rules by which matrices of real numbers are added and multiplied.

Note that if $R$ is any notrivial ring and $n\geq2$, then $M_n(R)$ is `not commutative`. And $M_n(R)$ has zero divisors for all nonzero rings $R$ whenever $n\geq 2$.

An element $(a_{ij})$ is called a `scalar matrix` if for some $a\in R$, $a_{ii}=a$ for all $i$ and $a_{ij}=0$ for all $i\neq j$ (i.e., diagonal equal $a$, i.e., $aI$). The set of scalar matrices is a subring of $M_n(R)$. This subring is a copy of $R$ (i.e., isomorphic): $(a+b)I = aI + bI$, $(ab)I = aIbI$. If $R$ is commutative, the scalar matrices commute with all elements of $M_n(R)$. If $R$ has $1$, then the scalar matrix with $1$'s down the diagonal is the $1$ of $M_n(R)$. In this case the units in $M_n(R)$ are the invertible matrices, and the group of units is denoted $GL_n(R)$, the `general linear group` of degree $n$ over $R$.

If $S$ is a subring of $R$ then $M_n(S)$ is a subring of $M_n(R)$. For instance, $M_n(\Z)$ is a subring of $M_n(\mathbb Q)$ and $M_n(2\Z)$ is a subring of both. Another example: `upper triangular` matrices, the product and sum of upper triangular matrices is upper triangular.

## Group Rings

Fix a commutative ring $R$ with identity $1\neq 0$ and let $G=\{g1,g_2,g_3,...,g_n\}$ be any finite group with group operation written multiplicatively. Define the `group ring`, $RG$, of $G$ with coefficients in $R$ to be the set of all formal sums
$$
a_1g_1+a_2g_2+\cdots+a_ng_n\qquad a_i\in R,\, 1\leq i\leq n
$$
If $g_1$ is the identity of $G$ we shall write $a_1g_1$ simply as $a_1$. Similarly, we shall write the element $1g$ for all $g\in G$ as $g$.

Addition is defined "componentwise", multiplicaion is performed by defining $(ag_i)(bg_j)=(ab)g_k$ where the product $ab$ is taken in $R$, and $g_ig_j=g_k$ is the product in group $G$.

The ring $RG$ is commutative if and only if $G$ is a commutative group.


